<html lang="en" class=" decnjcsxa idc0_350 dheiiaoprq">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
        <meta charset="utf-8">
        <title>IAN LOAM</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="shortcut icon" href="/static/favicon.ico" />
        <style>
	  html {overflow-y: scroll}
          body {max-width: 650px; min-height: 100% -10px; margin: 15px auto; padding: 0 10px; font: 18px/1.5 "Times New Roman", serif, "Times"; background-color: #fff; color: #333; border: 25px solid white;}

          nav, footer {text-indent: 30px}
          a {color: #333; font-style: italic; text-decoration: underline dotted; display: inline}
          a:hover {background-color: #222; color: #fff; text-decoration: none}
	  span {white-space: nowrap}
	  code {word-break: break-all; font-size: 12px}
          section {clear: both; border-left: 5px solid #eee; padding-left: 25px}
	  section img {max-height: 160px}
          h1, h2, h3 {color: #000; font-weight: 500; line-height: 1; font-family: "Times"}
	  ul {list-style-type: square; line-height: 1.4; list-style-position: outside}
	  ul img {max-height: .8em; max-width: 1em; vertical-align: middle}
          ::selection {color: #fff; background-color: #222}
	  hr {border-style: solid; border-color: #dedede}
	  .header-link {font-size: 2em; display: inline-block; margin-right: 10px; text-decoration: none; font-style: normal; color: #000; font-weight: 500; line-height: 1.2; font-family: "Times"}
        </style>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"></script>
	<script>
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']]
        }
    });
    MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
</script>

    </head>
    <body>
      <a href="/" class="header-link">Ian Loam</a> ▪ <a href="/library">Library</a> ▪ <a href="/resume.pdf">Resume</a>
    <hr>
	<main>



<img src="/static/notes.jpg" onerror="this.style.display='none'" style="display: block">

<h1 id="autodidacticism-and-research">Autodidacticism and Research</h1>


<h1 id="math-foundations-intuitionism-and-computation">Math Foundations: Intuitionism and Computation</h1>
<p><em>August 20, 2024</em></p>
<p>Understanding intuitionism, and</p>
<h2 id="1-background">1. Background</h2>
<p>There is often a tendency within scientific disciplines to dismiss advances made through qualitative research. While overtly technical approaches are universally appreciated for clear use of evidence and quantitative analysis for its results, qualitative research is perceived as less substantial for being too anecdotal, subjective or irrelevant.</p>
<p>This criticism would be fine if it is for acknowledging the risk involved in engaging with this kind of research, but there is a forgetfulness that anything quantitative can not stand on its own. The way you phrase and interpret a question, answer, or methodology relies entirely on qualitative factors. A wrong variable, new dimension or perspective can render a result entirely pointless or nonsensical without any change to the evidence or methods. The problems stemming from ignoring qualitative analysis can span much further than just needing to rephrase or add to outdated results, but can completely cut the value of entire fields.</p>
<p>In particular, with fields heavily dependent on theory, like mathematics, a qualitative ignorance would drive its results to being too detached from the world. Even with all the deep insightful answers that are produced and new creative questions that now exist, the theorems are empty and are ultimately just noise for closed-off groups to propogate between eachother. When the complications and paradoxes eventually arise, its easy to apologize for them by making exceptions or popularizing defective results as interesting novelties.</p>
<p>This is not to say that all of mathematics is useless, but it is clear that disregarding how mathematics is qualitatively framed sacrifices its authenticity and usefulness as a field.</p>
<h2 id="2-critique-of-mathematics">2. Critique of Mathematics</h2>
<p>What is to blame for this qualitative ignorance is how the current math foundations create a limited perspective for how proofs, theorems, etc. gain meaning within language.</p>
<p>Specifically, this treatment would be the standard foundation of ZFC-set theory, which broadly supports a metaphysical view of axiomatic Platonism. More concretely, this approach is to state a variety of semi-arbitrary axioms as a starting point, and through certain rules of inference, build up more and more theorems that imply new external mathematical objects. The role of ZFC axioms, in particular, is to be the most productive basis of other potential axiomatic systems, so, in theory, it would be a reference point to produce any mathematical object possible.</p>
<p>As well organized as this system is, it has the tendency to generate linguistic tricks suggesting the truth of theorems that are nonsensical.</p>
<h3 id="21-invisible-training-wheels">2.1. Invisible Training Wheels</h3>
<p>This issue lies in the assumption that proofs can reference objects that are external to the language you interpret at face value. To explain how this happens and why this is an issue, here is an analogy adapted from Hubert Dreyfus:</p>
<blockquote>
<p>When I learned to ride a bicycle I had training wheels because otherwise I would fall over. Now that I have some experience on the bicycle without the training wheels, I can ride the bike without falling over… Do I now have invisible training wheels?</p>
</blockquote>
<p>Clearly I am only balancing, but by knowing the past neccessity of training wheels we can suggest that these &ldquo;invisible training wheels&rdquo; would exist in our later state because if they were not there then there is a contradiction, I would have fallen over.</p>
<p>While on the bicycle it was the increase in skill that permitted you to not fall over without training wheels, why is it not that in mathematics an increase in subjective understanding or intuition that substitutes external mathematical objects?</p>
<p>If we were to write a proof by contradiction, then what stops our resulting theorem from also becoming &ldquo;invisible&rdquo;? Proving that a proposition P is true, by first negating it then finding some kind of contradiction, could turn a purely intuitive insight into &ldquo;invisible training wheels&rdquo; just like the bicycle analogy.</p>
<p>So, in practice, what would an intuititive insight and its resulting &ldquo;invisible training wheels&rdquo; look like? There might be endless examples, but a particularly simple one to see would be the Real numbers defined via infinite decimal expansion.</p>
<h3 id="22-square-root-of-2">2.2. Square Root of 2</h3>
<p>Historically, the first development of the Reals arised out of the ancient Greek discovery of irrational numbers with $\sqrt{2}$.</p>
<blockquote>
<p>As the story goes, a Pythagorean named Hippasus discovered that the diagonal of a unit square could not be expressed as a ratio of natural numbers, thus making it irrational.</p>
</blockquote>
<p>Yet, even though $\sqrt{2}$ is irrational, we can quickly see that it can be approximated with rational (or in this case decimal) numbers like $1.414$, $1.414213$, etc. with increasing levels of accuracy. So, the intuition behind this would be the anticipation we have to keep approximating this number without limit. But, since it is a contradiction to say it is not a fixed quantity (because we can see geometrically the diagonal line has a fixed length), then there must be a determinate numerical representation. This leads us to believe that we can define $\sqrt{2}$ as this infinite decimal expansion, $1.414&hellip;$, such that is entirely independent of how you might define $\sqrt{2}$ in terms of some finite geometrical construction or algebraic formula.</p>
<p>While I do not deny the existence of $\sqrt{2}$, when we look at its definition as $1.414&hellip;$ there are strange complications.</p>
<p>The most obvious of which is how handwavy and ill-defined the literal &ldquo;$&hellip;$&rdquo; in the notation can be. The next digit in the expansion has a certain degree of randomness, so there is not much of any tangible way to generate the digits unabmbiguously to give the &ldquo;$&hellip;$&rdquo; some clarity. So, this added &ldquo;$&hellip;$&rdquo; as an independent definition would leave the full numerical representation of $1.414&hellip;$ &ldquo;invisible&rdquo;, even though we have the intuition of endless potential approximation and the contradiction of being a fixed length tells us that there is a determinate representation.</p>
<p>However, to cope, you can defer to a pre-existing finite definition such as the geometrical construction or algebraic formula to generate the digits, which is fine. Yet this defeats the point of making infinite decimal expansions an independent definition for this number.</p>
<p>Where this gets troublesome is when the &ldquo;$&hellip;$&rdquo; notation shifts from not only masking the ambiguity of this individual number, but to implying the existence of other Real numbers without any finite representation to leverage off of.</p>
<p>We have the intuition that, because $1.414&hellip;$ is one example of a defined infinite decimal expansion, there is the potential for any decimal place to be interchanged with a new digit $0$-$9$. So, it would be by possibility alone, of changing any or all digits, that it constitutes the existence of Real numbers defined without being able to write the full expansion or summarize it in some finite representation.</p>
<p>To illustrate, imagine that we represent numbers as combination locks, where each wheel is a digit $0$-$9$. Say we had a lock with $3$ wheels and it is set to the number $123$. Even if we do not mechanically set it to some other number such as $111$, $432$, etc., we still know that each can exist on the lock because of what is possible under each wheel, regardless if we ever choose to set it to that number. Finding $1.414&hellip;$ would be as if we had found an infinitely expanding combination lock. Although we can not finitely represent every number on this lock, we can still say they exist because of the potential under each wheel.</p>
<p>While it is possible to know the existence of something without neccessarily naming it, the reality is that the only reason that we were able to get to $1.414..$. was by multiple finite approximations whose full result was always invisible. This prospect of interchanging the &ldquo;possible digit&rdquo; in the infinite expansion only arised from a pre-existing finite representation and not a self-contained infinite representation. Thus, the Real numbers that rely entirely on their infinite decimal expansion are always &ldquo;invisible&rdquo; because we never grasped any infinitely expanding &ldquo;combination lock&rdquo; from discovering $\sqrt{2}$.</p>
<h3 id="23-further-invisibility-and-coping-with-paradoxes">2.3. Further Invisibility and Coping with Paradoxes</h3>
<p>Often cases, the first response after seeing the issues behind infinite decimal expansions is to still try to affirm the general idea of Real numbers, but by some alternative justification. Some popular Real number constructions, for example, include construction via Dedekind cuts or Cauchy sequences.</p>
<p>The issue with this would be that both of these constructions (and also other potential alternatives) rely on the existence of infinite self-contained sets.</p>
<p>This follows much of the same problems that infinite decimal expansion also suffered from. However, instead of observing how the ability to forever approximate the square root of two led to an invisible infinite representation even though we can see it geometrically, the ability to endlessly include some next number in a finite set to approach the set of all natural numbers (for example) would also lead to another invisible infinite representation even though we know that there exists a natural number system (i.e. $ { 1 }$, ${ 1,2,3 }, { 1,2,3,4 } $ and so on does not lead to $\mathbb{N}= {1,2,3,&hellip;}$ even though they each are a natural number).</p>
<p>It is also noteworthy that this attempt to recover the Real numbers, while not erroneous to desire trying, lends an insight to the more general issue of paradox coping.</p>
<p>To illustrate this, it seems that whenever a significant paradox arises, such as Russell&rsquo;s Paradox in set theory, it is typically resolved by making some sort of exception for its existence instead of trying to understand any root cause.</p>
<p>In the case of Russell&rsquo;s Paradox, the solution often is just adding a new axiom to set theory that specifically accounted for this paradox (Axiom of Regularity in ZFC).</p>
<p>This becomes a problem as soon as you realize that putting a band-aid for each individual paradox only works as a short-term and superficial solution that permits future paradoxes to arise anyways.</p>
<p>Instead, to demonstrate how a more effective analysis would play out, it would have been better to investigate existing axioms, such as the Axiom of Choice in ZFC. This axiom was the rationale that led to invisible infinite sets, and permitted Russell&rsquo;s Paradox to occur along with future and still unresolved paradoxes such as the Banach-Tarski Paradox.</p>
<p>Overall, when it comes to paradoxes, it is neccessary to see past any sunk cost fallacy and ensure that the fundamentals are all in order, instead of trying to cope and argue around an issue.</p>
<h2 id="3-how-mathematics-really-works">3. How Mathematics Really Works</h2>
<p>Throughout the critique, the introduction of linguistic tricks, such as invisibility, indicated the neccessity of subjective understanding to determine judgements made in mathematics.</p>
<p>This is not to say that mathematics is in any way &ldquo;a matter of opinion&rdquo; or &ldquo;relative&rdquo;, but that mathematical truth is not exclusively known through language or any other explicit form of expression.</p>
<p>Instead, there is some sense of an integrated approach between language with more implicit knowledge like intuition.</p>
<h3 id="31-holism-and-psychology">3.1. Holism and Psychology</h3>
<p>In the bicycle analogy, it was the intrinsic skill for riding a bicycle that substituted the need for training wheels. However, when it comes to performing mathematics we do not see the capacity for any physical skill, rather a perceptiveness of patterns and ability to anticipate possible mathematical actions.</p>
<p>This perceptiveness and anticipation is better understood as the ability to comprehend context beyond a literal representation or theorem. We can see a whole without neccessarily being able to pin down every aspect systematically.</p>
<p>If we looked back at the square root of 2, we have this intuition that we can approximate it endlessly. But it is never as if we have knowledge of its final and infinite approximation, it is more as if we feel a horizon of actions to take without taking the steps to execute them. We anticipate this gap in our minds without it ever really being put on paper.</p>
<p>Like skillfulness on a bicycle, this understanding of context is another intrinsic ability, but with our mind instead of body.</p>
<p>In psychology, we see a concrete analogy of this mental phenomena through Gestalt theory:</p>
<blockquote>
<p>The Gestalt psychologists emphasized how humans do not simply perceive objects as isolated elements but rather as whole systems. They supported a holistic view where the whole is more than the sum of its parts, and gives rise to patterns (or gestalts) that exist without any explicit part to represent them.</p>
</blockquote>
<blockquote>
<p>This perspective contrasts with the reductionist view where &ldquo;a whole is equal to the sum of its parts&rdquo; and that any pattern is attributed to isolated components.</p>
</blockquote>
<p>If we saw mathematics in the Gestalt view, every mathematical expression is its own isolated element surrounded by &ldquo;intuitive gaps&rdquo; providing a context to the whole of other expressions yet not constituting its own explicit part.</p>
<p>On the other hand, in the reductionist view, we assume that everything, including &ldquo;intuitive gaps&rdquo;, are neccessarily another isolated part and relate to other mathematical expressions through explicit logic.</p>
<p>It is clear that our mathematical intuition mirrors the behaviour of Gestalt Psychology, but the current math foundations, however, confuse it for mirroring the reductionist view.</p>
<p>When we consider a mathematical object &ldquo;invisible&rdquo; (such as the square root of 2), it comes from the mistake of assuming that one of these &ldquo;intuitive gaps&rdquo; are another isolated part and allow us to apply the same formal logic.</p>
<p>In reality, what these &ldquo;intuitive gaps&rdquo; contribute is background for how we manipulate mathematical expressions but not what the mathematical expressions represent.</p>
<h2 id="4-new-foundations">4. New Foundations</h2>
<p>The quickest way to accomodate the earlier critique would be by keeping the formal axiomatic approach oriented around set theory and logic, but adapt it to accept intuitionistic logic and finitism.</p>
<p>While this is an entirely correct solution and addresses each core grievance, it is not the best way to envision our more holistic Gestalt view and integrate language with intuition.</p>
<p>Even though we take steps to avoid reductionist errors (like invisibility), the suggested solution still holds on to the underlying structure of reductionism because of its axiomatic and logical methodology.</p>
<p>We still speak of mathematical expressions as if they are only built out of parts and relate explicitly. We see this in how we isolate some core axioms, which build up step by step to logically relate and imply new theorems.</p>
<p>You would still assume that any intuitive insight is neccessarily an explicit part or expression, but now you are more picky about their rules, instead of treating them as genuine implicit knowledge.</p>
<p>So, while technically being correct, you narrow your perspective of mathematical truth through this structural baggage.</p>
<h3 id="41-finite-methods-and-informality">4.1. Finite Methods and Informality</h3>
<p>To combat this, it is better for math foundations to not rely on axioms or formal logic at all. Rather than isolating entire domains of mathematics by prescribing formalisms as underlying truths, instead .</p>
<p>Mathematics would be centered around the underlying human activity and processes that prove further theorems and conclusions. When you put axioms/logic in the background and emphasize the methods and finite steps, you allow for a more open-ended and context-aware exposition of your theorems and ideas.</p>
<p>Intuition would describe potential mathematical actions or broader context of the informal axioms, instead of needing to be imperfectly filtered down through formal structures. So, emphasizing finite methods avoids taking the imposed structure of formalism too literally and allows for intuitive insights to have more clarity.</p>
<h3 id="42-computation-and-descriptive-theories">4.2. Computation and Descriptive Theories</h3>
<p>When we take finite methods and informality into practice the evident organization of mathematics begins to resemble something closer to theoretical computer science.</p>
<p>Computers are finite machines, and can execute finite methods within some human programmed algorithm. While, informal axioms can be better looked at as descriptive theories of these programs. They outline how mathematical structures emerge out of these computational processes, rather than prescribing the existence of mathematical structure and how that imposes further structure.</p>
<p>Instead of proofs and logic, programs and computation determine mathematical results. The focus shifts from deriving formal truths to observing and describing how structure from mathematics arises. After observing programs, a descriptive theory would provide a narrative to elaborate for how computations operate and possibly provide predictions for how they would keep operating.</p>
<p>Mathematical rigor is now grounded on the reproducibility and reliability of programs over formal proof. Descriptive theories would articulate the principles and patterns that govern computational processes, subsequently outlining their consistency and predictability.</p>
<p>Mathematical understanding ultimately becomes context-dependent. It is shaped by the underlying computational environment and problems. If we begin to develop more fine-tuned theories on not just the particular computational processes but of computation itself they do not disrupt/change fundamental understandings but clarify our original ideas, while manipulating old axioms always risks ruining previously uncovered ideas.</p>
<h2 id="5-final-remarks">5. Final Remarks</h2>
<p>Overall, to fight off against the threat of declining qualitative standards within mathematics, a foundation based on Computation and Intuition is neccessary.</p>
<p>It is clear that without this that mathematics begins to ignore its underlying human activity and contextual understanding, subsequently producing nonsensical and superficial claims.</p>
<p>A methodology of reproducible programs and descriptive theories on the emergence of structure within computational processes should replace the dominant practices of formal proof-making and axiomatic frameworks.</p>
<p>The path forward demands we set aside attachment from what makes mathematics reductive with any coping that reinforces it, and embrace a more authentic and open view of mathematics.</p>


<h1 id="nonrepresentational-programming-and-multiparadigm-languages">Nonrepresentational Programming and Multiparadigm Languages</h1>
<h2 id="1-background">1. Background</h2>
<p>With Turing Completeness, we develop the idea of whatever is possible in one programming language is also possible in every other. However, this is only true if you narrow your perspective to acknowledge only the formal mathematics of computable functions, while ignoring any broader sense of practical application or language expressiveness. This is instantly clear with esoteric and Turing tarpit languages (such as Brainfuck, Malbolge, etc.) that may have none or limited I/O and abstraction capabilties, among other inconveniences. Implementing an algorithm that may be trivial in C or Python is next to impossible in these languages.</p>
<p>So, how do we measure when a language has not only achieved Turing Completeness, but also some kind of &ldquo;General Completeness&rdquo;?</p>
<p>The most evident answer would be by the language&rsquo;s features. Whether it supports certain data-structures, libraries, syntax, garbage collection, type systems, execution models, or any other particular surface aspect of the language implemented to give it structure. If we select a group of features then they can be applied to a defined use-case or problem.</p>
<p>Extending from this, we begin to develop the idea of programming paradigms. Which are families of features that work well toghether and aimed at resembling a specific style of programming (e.g. Imperative, Functional, OOP, etc.).</p>
<p>Thus, when it comes to &ldquo;General Completeness&rdquo;, it could be achieved through Multiparadigm languages. This is because by implementing a large diversity of programming styles, we accumulate the amount and combinations of features that would potentially hit a targeted use-case.</p>
<h2 id="2-critique-of-multiparadigm-languages">2. Critique of Multiparadigm Languages</h2>
<p>While Multiparadigm languages do provide a viable solution to General Completeness, their pursuit of attaining comprehensive features produces a landscape of needless complexity.</p>
<p>/For example, when learning the language for the first time, the user has to deal with an overload of options and frameworks. For some given problem, the user not only has to solve it but navigate through all the features to find the most appropriate approach. This creates another layer of confusion, and needlessly detracts from the labor it took solving that problem.</p>
<p>The paradigms are not always compatible. Features from one paradigm may not integrate seamlessly with those from another, creating edge cases and subtle bugs that can be difficult to diagnose and fix. Even when corrected by the developer, there is always the need for some specialized structure or idiomatic solution (wee see the rise of syntax sugars and conventions like Design Patterns within OOP languages), which in isolation appears convenient, but as they accumulate contribute to an increasingly irregular and unpredictable language.</p>
<p>The design of the language is never finished. Much of the work goes into accomodating new use-cases and for making features across paradigms cohesive, inflating the language and difficulties as time goes on.</p>
<p>Especially when it comes to popular languages with teams of developers, it seems there is a layer of internal politics and bureaucracy required for the continual envisioning of the language. Every decision becomes mediated and subject to petty oversights.</p>
<p>Overall, despite providing a path toward General Completeness, Multiparadigm languages come with endless strings attached. There is never a point of focus or reliability where you can think about the programming problem on its own./</p>
<h3 id="21-design-of-the-c-programming-language">2.1. Design of the C Programming Language</h3>
<p>/On the other hand, the design of the C programming language provides an example of this problem independent approach. While not achieving &ldquo;General Completeness&rdquo;, the design philosophy behind the language avoids the pitfalls of Multiparadigm languages through simplicity and a well-defined scope.</p>
<p>Inspired by the UNIX philosophy, C emphasizes &ldquo;doing one thing well&rdquo;. For C this is: creating efficient, direct mapping to machine instructions for system-level programming.
/</p>
<h2 id="3-use-structures-and-programming-paradigms">3. Use-Structures and Programming Paradigms</h2>
<p>It seems that between Multiparadigm languages and C we have to choose between General Completeness and problem independence. However, this separation only arises because of our analysis of language design via programming paradigms and features.</p>
<p>We understand that there is a diverse set of applications for programming from web design, low-level systems, etc. with each respective feature to accomodate them. If we were to imagine an expansive map of all features, languages like C would be a small and well established territory while Multiparadigm languages would be growing into every domain.</p>
<p>However, when analyzing this hypothetical map, we begin to see that the territories of features are not as neatly defined as one might think. The boundaries between features tend to blur and overlap. Certain features can be dependent on eachother in unexpected ways, or the same feature can have differing limitations/capabilities depending on the context.</p>
<p>In fact, if we were to ask what is meant by a &ldquo;feature&rdquo;, we see there could not be a more confused term. Even though we can identify a singular feature at face value, it is far from clear what aspects are just &ldquo;details&rdquo; and what is essential for a language&rsquo;s underlying use.</p>
<p>To illustrate, if we were to look at two different languages with the same feature we often observe they mean very different things.</p>
<p>For example, take Lambdas in C++ and Python: in Python (and other interpreted languages) lambdas are executed symbolically by making substitutions to the lambda function directly through the interpreter runtime, but C++ is a compiled language that can not handle symbolic manipulations like this, so lambdas are treated as a black box from a special Functor class which is then compiled and run later from an executable file.</p>
<p>Although the lambdas from both languages ostensibly act the same, the differences in implementation tells us that the mechanism behind what produces the feature&rsquo;s usage comes from a fundamentally different organization and execution process.</p>
<p>We might ask: If they end up being used as the same feature then why do we care about implementation?</p>
<p>The first and obvious answer is that the differences in implementation makes them a different feature, but only in subtle ways. Maybe if we had some problem that asks us to pay close attention to precise details about how lambdas are executed (such as optimization problems or a problem concerning compiler limitations) then we care if the language uses a Functor class or interpreter substitution.</p>
<p>However, more interestingly it</p>
<p>What different manifestations of more fundamental programming concepts.</p>
<p>More abstractly,</p>
<h3 id="31-primitive-use-structures">3.1. Primitive Use-Structures</h3>
<p>More generally, if we were</p>
<h3 id="32-hybrid-compilers">3.2. Hybrid Compilers</h3>
<h2 id="4-nonrepresentational-languages">4. Nonrepresentational Languages</h2>
<h3 id="41-design-principles">4.1. Design Principles</h3>
<h3 id="42-key-features">4.2. Key features</h3>
<h3 id="43-implementation">4.3. Implementation</h3>
<h2 id="5-implications-and-future-directions">5. Implications and Future Directions</h2>
<h2 id="6-conclusion-and-final-remarks">6. Conclusion and Final Remarks</h2>


<h1 id="notes-on-algebra">Notes on Algebra</h1>


</main>
<hr>
<footer><p>Copyright (c) 2025, Ian Loam</p></footer>
</body>
</html>

